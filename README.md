# StreamBus

<div align="center">

**A next-generation distributed streaming platform built for performance, reliability, and operational simplicity**

[![Go Version](https://img.shields.io/badge/Go-1.23+-00ADD8?style=flat&logo=go)](https://golang.org)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Test Coverage](https://img.shields.io/badge/Coverage-100%25-brightgreen)](docs/TESTING.md)
[![Production Ready](https://img.shields.io/badge/Status-Development-yellow)](docs/ROADMAP.md)

[Features](#key-capabilities) ‚Ä¢ [Performance](#performance) ‚Ä¢ [Quick Start](#quick-start) ‚Ä¢ [Documentation](#documentation) ‚Ä¢ [Community](#community)

</div>

---

## Why StreamBus?

StreamBus is a high-performance, distributed streaming platform designed for modern cloud-native applications. If you're dealing with real-time data streams, event-driven architectures, or need a Kafka alternative with better performance characteristics, StreamBus delivers:

- **üöÄ 10-100x Lower Latency**: Sub-millisecond operations vs multi-millisecond batch processing
- **üí∞ 95% Lower Memory**: <100MB footprint vs multi-GB JVM heaps
- **‚ö° Instant Startup**: Cold start in <1 second vs 15-45 second JVM initialization
- **üõ†Ô∏è Zero Complexity**: Single binary, no JVM tuning, no ZooKeeper dependency
- **üîí Enterprise-Grade**: Built-in circuit breakers, health checks, structured logging, and metrics

Perfect for microservices, event sourcing, log aggregation, real-time analytics, and IoT data pipelines.

---

## Key Capabilities

### Built for Performance

- **Sub-Millisecond Latency**: ~25¬µs producer latency, perfect for latency-sensitive applications
- **Memory Efficient**: Runs comfortably in containers with minimal resource allocation
- **Fast Recovery**: Cold start and failover in under 1 second
- **Optimized Storage**: Custom LSM-tree engine with efficient compaction and indexing

### Production Hardened

- **Circuit Breaker Pattern**: Automatic fail-fast with configurable thresholds
- **Health Monitoring**: Kubernetes-ready liveness and readiness probes
- **Structured Logging**: JSON-formatted logs with contextual fields for observability
- **Prometheus Metrics**: Native metrics export for comprehensive monitoring
- **Smart Error Handling**: Categorized errors with automatic retry strategies
- **Timeout Management**: Centralized timeout configuration for consistent behavior

### Operationally Simple

- **Single Binary Deployment**: No complex setup, no external dependencies
- **Minimal Configuration**: Sensible defaults with configuration validation
- **Container Native**: Optimized for Docker, Kubernetes, and cloud platforms
- **Self-Contained**: No ZooKeeper, no complex coordination layer
- **Easy Troubleshooting**: Comprehensive health checks and diagnostic endpoints

### Developer Friendly

- **Idiomatic Go Client**: Clean, type-safe API with excellent documentation
- **Automatic Batching**: Smart batching for optimal throughput without sacrificing latency
- **Connection Pooling**: Built-in connection management with health checks
- **Retry Logic**: Exponential backoff with configurable retry policies
- **Rich Examples**: Production-ready examples for common use cases

---

## Use Cases

**Microservices Communication**
- Event-driven architecture between services
- Asynchronous command and query handling
- Service-to-service messaging with guaranteed delivery

**Real-Time Analytics**
- Streaming data ingestion for analytics pipelines
- Low-latency metric collection and aggregation
- Event stream processing for dashboards

**Event Sourcing & CQRS**
- Persistent event store with replay capabilities
- Command and event separation
- Temporal queries and projections

**Log Aggregation**
- Centralized logging from distributed systems
- High-throughput log collection
- Searchable log streams

**IoT Data Processing**
- Sensor data ingestion at scale
- Edge-to-cloud data streaming
- Real-time device telemetry

**Change Data Capture (CDC)**
- Database change streams
- Data synchronization across systems
- Audit trail and compliance logging

---

## Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             ‚îÇ       ‚îÇ       StreamBus Cluster         ‚îÇ       ‚îÇ             ‚îÇ
‚îÇ  Producers  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Consumers  ‚îÇ
‚îÇ             ‚îÇ       ‚îÇ  ‚îÇ Broker 1 ‚îÇ  ‚îÇ Broker 2 ‚îÇ   ‚îÇ       ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ  ‚îÇ (Leader) ‚îÇ  ‚îÇ(Follower)‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                      ‚îÇ       ‚îÇ              ‚îÇ         ‚îÇ
                      ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
                      ‚îÇ              ‚ñº                  ‚îÇ
                      ‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
                      ‚îÇ      ‚îÇ Raft Consensus‚îÇ         ‚îÇ
                      ‚îÇ      ‚îÇ   (Metadata)  ‚îÇ         ‚îÇ
                      ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
                      ‚îÇ                                 ‚îÇ
                      ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
                      ‚îÇ   ‚îÇ  LSM Storage Engine ‚îÇ      ‚îÇ
                      ‚îÇ   ‚îÇ   + Write-Ahead Log ‚îÇ      ‚îÇ
                      ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Core Components:**
- **LSM-Tree Storage**: Write-optimized storage with efficient compaction
- **Raft Consensus**: Leader election and metadata coordination without ZooKeeper
- **Binary Protocol**: Efficient custom protocol for low-latency communication
- **Replication**: Leader-follower topology with in-sync replica tracking
- **Health System**: Comprehensive health checks for all components

---

## Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/shawntherrien/streambus.git
cd streambus

# Install dependencies
go mod download

# Run tests to verify
go test ./...

# Build the server
go build -o bin/streambus cmd/server/main.go
```

### Running StreamBus

```bash
# Start the server
./bin/streambus --port 9092

# Server starts with:
# - Binary protocol on port 9092
# - Health checks on port 8080
# - Metrics endpoint on port 8080/metrics
```

### Using the Client

```go
package main

import (
    "context"
    "fmt"
    "log"

    "github.com/shawntherrien/streambus/pkg/client"
)

func main() {
    // Connect to StreamBus
    config := client.DefaultConfig()
    config.Brokers = []string{"localhost:9092"}

    c, err := client.New(config)
    if err != nil {
        log.Fatal(err)
    }
    defer c.Close()

    // Create a topic
    if err := c.CreateTopic("orders", 3, 1); err != nil {
        log.Fatal(err)
    }

    // Produce messages
    producer := client.NewProducer(c)
    defer producer.Close()

    ctx := context.Background()
    err = producer.Send(ctx, "orders", []byte("order-123"), []byte(`{
        "orderId": "123",
        "amount": 99.99,
        "status": "pending"
    }`))
    if err != nil {
        log.Fatal(err)
    }

    // Consume messages
    consumer := client.NewConsumer(c, "orders", 0)
    defer consumer.Close()

    consumer.SeekToBeginning()
    messages, err := consumer.Fetch(ctx)
    if err != nil {
        log.Fatal(err)
    }

    for _, msg := range messages {
        fmt.Printf("Received: %s\n", msg.Value)
    }
}
```

See [examples/](examples/) for complete producer and consumer examples.

---

## Performance

**Test Environment**: Apple M4 Max, 16 cores, Go 1.23

### Key Metrics

| Metric | StreamBus | Typical Kafka | Advantage |
|--------|-----------|---------------|-----------|
| **Producer Latency** | 25 ¬µs | 0.5-5 ms | **20-200x faster** |
| **Memory Footprint** | <100 MB | 2-8 GB | **95% less memory** |
| **Cold Start** | <1 second | 15-45 seconds | **15-45x faster** |
| **GC Pauses** | <1 ms | 10-200 ms | **10-200x less pause time** |
| **Binary Size** | 15 MB | N/A (JVM) | Single binary deployment |

### Detailed Benchmarks

**Client Operations** (End-to-End):
- Producer Send: 25.1 ¬µs/op, ~40,000 msg/s
- Consumer Fetch: 21.8 ¬µs/op, ~46,000 fetch/s

**Storage Layer** (LSM-Tree):
- Write: 1,095 ns/op (single), 5,494 ns/op (batch)
- Read: 140 ns/op from MemTable
- WAL Append: 919 ns/op (buffered), 8.5 ms/op (synced)

**Protocol Layer** (Serialization):
- Encode Produce: 38.6 ns/op
- Decode Produce: 110 ns/op
- Encode Fetch: 21.6 ns/op
- Decode Fetch: 70.5 ns/op

See [docs/BENCHMARKS.md](docs/BENCHMARKS.md) for comprehensive performance analysis.

---

## Production Features

### Observability

**Health Checks**
- `/health` - Comprehensive component health
- `/health/live` - Kubernetes liveness probe
- `/health/ready` - Kubernetes readiness probe

**Metrics** (Prometheus-compatible)
- Request rates and latencies
- Storage statistics
- Replication lag
- Circuit breaker states
- Resource utilization

**Structured Logging**
- JSON-formatted logs
- Contextual fields (component, operation, request ID)
- Configurable log levels
- Error categorization

### Reliability

**Circuit Breakers**
- Automatic fail-fast for unhealthy dependencies
- Configurable failure thresholds
- Half-open testing for recovery
- State change callbacks

**Error Handling**
- Categorized errors (Retriable, Transient, Fatal, Invalid Input)
- Automatic retry with exponential backoff
- Context preservation through error chains
- Detailed error metadata

**Timeout Management**
- Centralized timeout configuration
- Context-based timeout enforcement
- Operation-specific timeout strategies
- Runtime configuration updates

### Deployment

**Container Native**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: streambus
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: streambus
        image: streambus:latest
        ports:
        - containerPort: 9092
          name: protocol
        - containerPort: 8080
          name: health
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8080
          initialDelaySeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8080
          initialDelaySeconds: 5
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
```

**Docker**
```bash
# Build
docker build -t streambus:latest .

# Run
docker run -p 9092:9092 -p 8080:8080 streambus:latest
```

---

## Documentation

### Getting Started
- [Quick Start Guide](docs/GETTING_STARTED.md) - Step-by-step tutorial
- [Examples](examples/README.md) - Complete producer and consumer examples
- [API Reference](docs/api-reference.md) - Comprehensive API documentation

### Operations
- [Deployment Guide](docs/operations.md) - Production deployment and operations
- [Configuration Reference](docs/configuration.md) - Complete configuration options
- [Production Hardening](docs/PRODUCTION_HARDENING_USAGE.md) - Reliability and observability features
- [Monitoring](docs/monitoring.md) - Metrics, logging, and health checks

### Architecture
- [Architecture Overview](docs/ARCHITECTURE.md) - System design and components
- [Storage Engine](docs/storage-engine.md) - LSM-tree implementation details
- [Consensus Protocol](docs/consensus.md) - Raft implementation
- [Replication](docs/replication.md) - Leader-follower replication

### Migration
- [Migrating from Kafka](docs/migration-from-kafka.md) - Migration guide and tools
- [Compatibility](docs/kafka-compatibility.md) - Kafka compatibility layer

### Development
- [Contributing Guide](CONTRIBUTING.md) - How to contribute
- [Development Setup](docs/development.md) - Local development environment
- [Testing Guide](docs/TESTING.md) - Test strategy and coverage
- [Benchmarking](docs/BENCHMARKS.md) - Performance benchmarks and methodology

---

## Development Status

StreamBus is currently in **active development** with production-ready core components.

### ‚úÖ Complete

**Phase 1: Core Platform**
- ‚úÖ LSM-tree storage engine with WAL (27/27 tests)
- ‚úÖ Binary protocol layer (100% coverage)
- ‚úÖ Producer and consumer clients (22/22 tests)
- ‚úÖ Server request handling
- ‚úÖ End-to-end integration (5/5 tests)

**Phase 2: Distributed System**
- ‚úÖ Raft consensus implementation (36/36 tests)
- ‚úÖ Metadata store with replication (8/8 tests)
- ‚úÖ Cluster coordination (10/10 tests)
- ‚úÖ Leader election and failover
- ‚úÖ Multi-broker replication

**Phase 2.6: Production Hardening**
- ‚úÖ Circuit breaker pattern (14/14 tests)
- ‚úÖ Health check system (18/18 tests)
- ‚úÖ Enhanced error handling (30/30 tests)
- ‚úÖ Prometheus metrics (29/29 tests)
- ‚úÖ Structured logging (24/24 tests)
- ‚úÖ Timeout management (29/29 tests)

**Total: 252 tests passing (100% coverage)**

### üöß In Progress

**Phase 3: Advanced Features**
- üîÑ Consumer groups with rebalancing
- üîÑ Transactions and exactly-once semantics
- üîÑ Schema registry integration

**Phase 4: Enterprise Features**
- üîÑ Access control and authentication
- üîÑ Encryption at rest and in transit
- üîÑ Multi-tenancy support

See [docs/ROADMAP.md](docs/ROADMAP.md) for the complete roadmap.

---

## Why Choose StreamBus?

### vs Apache Kafka

| Feature | StreamBus | Apache Kafka |
|---------|-----------|--------------|
| **Latency** | Sub-millisecond (25¬µs) | Milliseconds (0.5-5ms) |
| **Memory** | <100 MB | 2-8 GB |
| **Startup** | <1 second | 15-45 seconds |
| **Deployment** | Single binary | JVM + ZooKeeper |
| **Tuning** | Minimal config | Extensive JVM tuning |
| **Dependencies** | None | ZooKeeper required |
| **Language** | Go (modern runtime) | Java/Scala (JVM) |
| **Use Case** | Low-latency, real-time | High-throughput, batch |

**Choose StreamBus if you need:**
- Lower latency and faster response times
- Smaller resource footprint
- Simpler operations and deployment
- Cloud-native, container-friendly architecture
- Modern Go-based development

**Choose Kafka if you need:**
- Massive batch throughput (millions msg/s)
- Extensive ecosystem of connectors
- Battle-tested production maturity
- Large community and support

### vs NATS

| Feature | StreamBus | NATS Streaming |
|---------|-----------|----------------|
| **Persistence** | Full LSM-tree with compaction | Memory-first with overflow |
| **Consensus** | Raft (built-in) | NATS clustering |
| **Storage** | Optimized for disk | Memory-optimized |
| **Replication** | Multi-broker with ISR | NATS JetStream |
| **Use Case** | Durable streaming | Lightweight messaging |

**Choose StreamBus for:** Durable event storage, replay capabilities, large message volumes

**Choose NATS for:** Lightweight pub-sub, minimal latency, ephemeral messaging

---

## Community & Support

### Get Help

- üìñ **Documentation**: [Complete docs](docs/)
- üí¨ **Discussions**: [GitHub Discussions](https://github.com/shawntherrien/streambus/discussions)
- üêõ **Issues**: [GitHub Issues](https://github.com/shawntherrien/streambus/issues)
- üîí **Security**: Report vulnerabilities to security@streambus.io

### Stay Updated

- ‚≠ê **Star** this repo to follow development
- üëÄ **Watch** for release notifications
- üê¶ **Twitter**: [@streambus](https://twitter.com/streambus)
- üìù **Blog**: [blog.streambus.io](https://blog.streambus.io)

### Contributing

We welcome contributions! StreamBus is open source and community-driven.

```bash
# Fork and clone
git clone https://github.com/YOUR_USERNAME/streambus.git

# Create a feature branch
git checkout -b feature/amazing-feature

# Make changes and test
go test ./...

# Submit a pull request
```

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## Production Readiness

**Current Status**: **Development** (Phase 2 Complete)

StreamBus has completed core distributed system features with production-grade reliability patterns. However, it is **not yet recommended for production use** until the following are completed:

### Required for Production
- [ ] Security: TLS, authentication, authorization
- [ ] Advanced replication: Cross-datacenter
- [ ] Monitoring: Complete observability stack
- [ ] Performance: Large-scale production testing
- [ ] Documentation: Complete operational guides

### Estimated Timeline
- **Q2 2025**: Security and authentication
- **Q3 2025**: Beta testing program
- **Q4 2025**: Production-ready release

**Want to help?** Join our [beta testing program](docs/beta-testing.md)!

---

## License

StreamBus is released under the **Apache 2.0 License**. See [LICENSE](LICENSE) for details.

```
Copyright 2025 StreamBus Contributors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0
```

---

## Acknowledgments

StreamBus is inspired by the groundbreaking work of:
- **Apache Kafka** - For establishing distributed streaming patterns
- **Raft Consensus** - For elegant distributed consensus
- **LSM-Tree research** - For efficient write-optimized storage
- **Go community** - For an exceptional runtime and ecosystem

Built with ‚ù§Ô∏è in Go by developers who believe streaming platforms should be fast, simple, and reliable.

---

<div align="center">

**[Get Started](docs/GETTING_STARTED.md)** ‚Ä¢ **[View Examples](examples/)** ‚Ä¢ **[Read Docs](docs/)** ‚Ä¢ **[Join Community](https://github.com/shawntherrien/streambus/discussions)**

‚≠ê **Star us on GitHub** ‚Äî it helps!

</div>
